#!/usr/bin/env python3

import argparse
import copy
import os
import pathlib
import requests
import textwrap
import time
from typing import Any, Dict, List, Mapping, Optional, Tuple, Union

from cvelib.cve import checkSyntax, _getCVEPaths, CVE
from cvelib.common import (
    getConfigCveDataPaths,
    getConfigCompatUbuntu,
    error,
    rePatterns,
    updateProgress,
    warn,
)

# TODO: pass these around
repos_all: List[str] = []  # list of repos
issues_all: Dict[str, List[str]] = {}  # keys are repos, values are lists of issue urls
issues_ind: Dict[
    str, Mapping[str, Any]
] = {}  # keys are 'repo/num', values are arbitrary json docs from GitHub


def _requestGetRaw(
    url: str, headers: Dict[str, str] = {}, params: Mapping[str, Union[str, int]] = {}
) -> requests.Response:
    """Wrapper around requests.get()"""
    hdrs: Dict[str, str] = copy.deepcopy(headers)
    if len(hdrs) == 0:
        if "GHTOKEN" in os.environ:
            hdrs["Authorization"] = "token %s" % os.getenv("GHTOKEN")

    # print("DEBUG: url=%s, headers=%s, params=%s" % (url, hdrs, params))
    return requests.get(url, headers=hdrs, params=params)


# TODO: type hint the return value (it's tricky)
def _requestGet(
    url: str, headers: Dict[str, str] = {}, params: Mapping[str, Union[str, int]] = {}
):
    """Wrapper around requests.get() for json"""
    r: requests.Response = _requestGetRaw(url, headers, params)
    if r.status_code >= 400:
        error("Problem fetching %s:\n%d - %s" % (url, r.status_code, r.json()))

    return r.json()


# https://docs.github.com/en/graphql/reference/objects#repositoryvulnerabilityalert
#
# GraphQL can be used on repos that have dependabot enabled. Oddly, there
# doesn't seem to be a way to see 'active' alerts. It seems that one would
# have to pull down the dependency graph (DependencyGraphDependency?) then
# see if anything in the RepositoryVulnerabilityAlerts are affected by looking
# at the versions....
#
# Eg:
# query = '''
# {
#   repository(name: "%s", owner: "%s") {
#     vulnerabilityAlerts(first: 100) {
#       nodes {
#         createdAt
#         dismissedAt
#         dismissReason
#         dismisser {
#           name
#         }
#         securityVulnerability {
#           package {
#             name
#           }
#           severity
#           advisory {
#             description
#           }
#         }
#         vulnerableManifestPath
#         securityAdvisory {
#           permalink
#         }
#       }
#     }
#   }
# }
# ''' % (repo, org)
# TODO: type hint the return value (it's tricky)
def _queryGraphQL(query: str, headers: Dict[str, str] = {}):
    """Wrapper around requests.post() for graphql"""
    url = "https://api.github.com/graphql"
    hdrs: Dict[str, str] = copy.deepcopy(headers)
    if len(hdrs) == 0:
        if "GHTOKEN" in os.environ:
            hdrs["Authorization"] = "token %s" % os.getenv("GHTOKEN")

    # TODO: handle rate limits:
    # https://docs.github.com/en/graphql/overview/resource-limitations
    r: requests.Response = requests.post(url, json={"query": query}, headers=hdrs)
    if r.status_code != 200:
        error("Problem querying %s. %d - %s" % (url, r.status_code, query))

    return r.json()


def _getGHReposAll(org: str) -> List[str]:
    """Obtain the list of GitHub repos for the specified org"""
    global repos_all
    if len(repos_all) > 0:
        print("Using previously fetched list of repos")
        return copy.deepcopy(repos_all)

    url: str = "https://api.github.com/orgs/%s/repos" % org
    params: Dict[str, Union[str, int]] = {
        "accept": "application/vnd.github.v3+json",
        "per_page": 100,
    }

    print("Fetching list of repos: ", end="", flush=True)
    count: int = 0
    while True:
        count += 1
        print(".", end="", flush=True)
        params["page"] = count

        resj = _requestGet(url, params=params)
        if len(resj) == 0:
            print(" done!")
            break

        for repo in resj:
            if "name" in repo:
                repos_all.append(repo["name"])

    return copy.deepcopy(repos_all)


def _getGHIssuesForRepo(
    repo: str, org: str, labels: List[str] = [], skip_labels: List[str] = []
) -> List[str]:
    """Obtain the list of GitHub issues for the specified repo and org"""
    global issues_all
    if repo in issues_all:
        print("Using previously fetched list of issues for %s" % repo)
        return sorted(copy.deepcopy(issues_all[repo]))

    url: str = "https://api.github.com/repos/%s/%s/issues" % (org, repo)
    params: Dict[str, Union[str, int]] = {
        "accept": "application/vnd.github.v3+json",
        "per_page": 100,
    }
    query_labels: List[str] = [""]
    if len(labels) > 0:
        query_labels = labels

    print(" %s/%s: " % (org, repo), end="", flush=True)
    query_label: str
    for query_label in query_labels:
        count: int = 0
        while True:
            count += 1
            print(".", end="", flush=True)
            params["page"] = count

            if query_label != "":
                params["labels"] = query_label

            r: requests.Response = _requestGetRaw(url, params=params)
            if r.status_code == 410:  # repo turned off issues
                # warn("Skipping %s (%d) - issues turned off" % (url, r.status_code))
                return []
            elif r.status_code == 404:
                warn("Skipping %s (%d)" % (url, r.status_code))
                return []
            elif r.status_code >= 400:
                error(
                    "Problem fetching %s:\n%d - %s" % (url, r.status_code, r.json()),
                    do_exit=False,
                )
                return []

            resj = r.json()
            if len(resj) == 0:
                break

            issue: Dict[str, Any]
            for issue in resj:
                # check if issue has any of the labels that we designated if
                # present, we should skip
                if len(skip_labels) > 0 and "labels" in issue:
                    found: bool = False
                    i: Dict[str, Any]
                    for i in issue["labels"]:
                        if "name" in i and i["name"] in skip_labels:
                            found = True
                    if found:
                        continue

                if "pull_request" in issue and len(issue["pull_request"]) > 0:
                    continue  # skip pull requests
                if "html_url" in issue:
                    if repo not in issues_all:
                        issues_all[repo] = []
                    issues_all[repo].append(issue["html_url"])
    print(" done!")

    if repo in issues_all:
        return sorted(copy.deepcopy(issues_all[repo]))
    return []  # repo with turned off issues


def _getGHIssue(repo: str, org: str, number: int) -> Mapping[str, Any]:
    """Obtain the GitHub issue for the specified repo, org and issue number"""
    global issues_ind
    k: str = "%s/%d" % (repo, number)
    if k in issues_ind:
        print("Using previously fetched issue for %s" % k)
        return issues_ind[k]

    url: str = "https://api.github.com/repos/%s/%s/issues/%d" % (org, repo, number)
    params: Dict[str, Union[str, int]] = {"accept": "application/vnd.github.v3+json"}

    r: requests.Response = _requestGetRaw(url, params=params)
    if r.status_code == 410:  # repo turned off issues
        # warn("Skipping %s (%d) - issues turned off" % (url, r.status_code))
        return {}
    elif r.status_code == 404:
        warn("Skipping %s (%d)" % (url, r.status_code))
        return {}
    elif r.status_code >= 400:
        error(
            "Problem fetching %s:\n%d - %s" % (url, r.status_code, r.json()),
            do_exit=False,
        )
        return {}

    issues_ind[k] = r.json()
    return issues_ind[k]


def _getKnownIssues(
    cves: List[CVE], filter_url: Optional[str] = None
) -> Dict[str, List[str]]:
    """Obtain the list of URLs in our CVE info"""

    def _collectable(url: str, filter: Optional[str]) -> bool:
        if rePatterns["github-issue"].match(url):
            if filter is None or "/%s/" % filter in url:
                return True
        return False

    urls: Dict[str, List[str]] = {}
    for cve in cves:
        for u in cve.references + cve.bugs:
            url: str = u.split()[0]
            if _collectable(url, filter_url):
                # strip off GH comments
                if url.startswith("https://github.com") and "#" in url:
                    url = url.split("#")[0]
                if url not in urls:
                    urls[url] = []
                if cve.candidate not in urls[url]:
                    urls[url].append(cve.candidate)

    return urls


def getMissingReport(
    cves: List[CVE],
    org: str,
    repos: List[str] = [],
    excluded_repos: List[str] = [],
    labels: List[str] = [],
    skip_labels: List[str] = [],
) -> None:
    """Compare list of issues in issue trackers against our CVE data"""
    known_urls: Dict[str, List[str]] = _getKnownIssues(cves, filter_url=org)

    fetch_repos: List[str] = repos
    if len(fetch_repos) == 0:
        fetch_repos = _getGHReposAll(org)

    gh_urls: List[str] = []
    print("Fetching list of issues for:")
    for repo in sorted(fetch_repos):
        if repo in excluded_repos:
            continue

        url: str
        for url in _getGHIssuesForRepo(
            repo, org, labels=labels, skip_labels=skip_labels
        ):
            if url not in known_urls and url not in gh_urls:
                gh_urls.append(url)

    if len(gh_urls) == 0:
        print("No missing issues for the specified repos.")
    else:
        print("Issues missing from CVE data:")
        for url in gh_urls:
            print(" %s" % url)


def _getGHAlertsEnabled(
    org: str, repos: List[str] = [], excluded_repos: List[str] = []
) -> Tuple[List[str], List[str]]:
    fetch_repos: List[str] = repos
    if len(fetch_repos) == 0:
        fetch_repos = _getGHReposAll(org)

    enabled: List[str] = []
    disabled: List[str] = []

    # Unfortunately there doesn't seem to be an API to tell us all the repos
    # with dependabot alerts, so get a list of URLs and then see if enabled or
    # not
    count: int = 0
    for repo in sorted(fetch_repos):
        if repo in excluded_repos:
            continue

        count += 1
        updateProgress(count / len(fetch_repos), prefix="Collecting repo status: ")

        url: str = "https://api.github.com/repos/%s/%s/vulnerability-alerts" % (
            org,
            repo,
        )
        params: Dict[str, Union[str, int]] = {
            "accept": "application/vnd.github.v3+json"
        }

        res: requests.Response = _requestGetRaw(url, params=params)
        if res.status_code == 204:
            # enabled
            enabled.append(repo)
        elif res.status_code == 404:
            # disabled
            disabled.append(repo)
        else:
            error("Problem fetching %s:\n%d - %s" % (url, res.status_code, res))

    return enabled, disabled


def getGHAlertsStatusReport(
    org: str, repos: List[str] = [], excluded_repos: List[str] = []
) -> None:
    """Obtain list of repos that have vulnerability alerts enabled/disabled"""
    enabled: List[str]
    disabled: List[str]
    enabled, disabled = _getGHAlertsEnabled(org, repos, excluded_repos=excluded_repos)
    print("Enabled:\n%s" % "\n".join(" %s" % r for r in enabled))
    print("Disabled:\n%s" % "\n".join(" %s" % r for r in disabled))


def getUpdatedReport(cves: List[CVE], org: str, since: int = 0) -> None:
    """Obtain list of URLs that have received an update since last run"""
    urls: Dict[str, List[str]] = _getKnownIssues(cves, filter_url=org)

    # convert since to a date string that we can lexigraphically compare to the
    # github string
    if not isinstance(since, int) or since < 0:
        raise ValueError
    since_str: str = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(since))

    # find updates
    updated_urls: List[str] = []
    count: int = 0
    for url in sorted(urls.keys()):
        count += 1
        updateProgress(count / len(urls), prefix="Collecting known issues: ")

        # TODO: break this out
        if not rePatterns["github-issue"].match(url):
            continue  # only support github issues at this time
        tmp: List[str] = url.split("/")

        # compare the issue's updated_at with our since time
        issue: Mapping[str, Any] = _getGHIssue(tmp[4], tmp[3], int(tmp[6]))
        if "updated_at" in issue and issue["updated_at"] > since_str:
            updated_urls.append(url)

    if len(updated_urls) == 0:
        print("No updated issues for the specified repos.")
    else:
        print("Updated issues:")
        for url in updated_urls:
            print(" %s (%s)" % (url, ", ".join(urls[url])))


def _printGHAlertsUpdatedSummary(
    org: str, repo: str, alert: List[Dict[str, str]]
) -> None:
    """Print out the alert summary"""
    url: str = "https://github.com/%s/%s/security/dependabot" % (org, repo)
    print("%s alerts: %d (%s)" % (repo, len(alert), url))

    # for n in alert:
    for n in sorted(alert, key=lambda i: (i["pkg"], i["created"])):
        print("  %s" % n["pkg"])
        print("    - severity: %s" % n["severity"])
        print("    - created: %s" % n["created"])
        print("    - %s" % n["path"])
        print("    - %s" % n["ghsa"])
        print("")


def _printGHAlertsDismissedSummary(
    org: str, repo: str, alert: List[Dict[str, str]]
) -> None:
    """Print out the alert summary"""
    url: str = "https://github.com/%s/%s/security/dependabot" % (org, repo)
    print("%s dismissed alerts: %d (%s)" % (repo, len(alert), url))

    # for n in alert:
    for n in sorted(alert, key=lambda i: (i["pkg"], i["dismissed"])):
        print("  %s" % n["pkg"])
        print("    - severity: %s" % n["severity"])
        print("    - dismissed: %s" % n["dismissed"])
        print("    - reason: %s" % n["reason"])
        if n["name"] is not None:
            print("    - by: %s" % n["name"])
        print("    - %s" % n["path"])
        print("    - %s" % n["ghsa"])
        print("")


def _printGHAlertsUpdatedTemplates(
    org: str, repo: str, alert: List[Dict[str, str]]
) -> None:
    """Print out the updated alerts issue templates"""
    sev: List[str] = ["unknown", "low", "moderate", "high", "critical"]
    highest: int = 0

    items: Dict[str, int] = {}
    for n in alert:
        s: str = "- [ ] %s (%s)" % (n["pkg"], n["severity"])
        if s not in items:
            items[s] = 1
        else:
            items[s] += 1

        cur: int
        try:
            cur = sev.index(n["severity"])
        except ValueError:
            cur = sev.index("unknown")

        if cur > highest:
            highest = cur

    checklist: str = ""
    i: str
    for i in sorted(items.keys()):
        if items[i] > 1:
            checklist += "%s\n" % (i.replace("(", "(%d " % (items[i])))
        else:
            checklist += "%s\n" % i

    priority: str = sev[highest]
    if priority == "moderate" or priority == "unknown":
        priority = "medium"

    print("## %s template" % repo)
    url: str = "https://github.com/%s/%s/security/dependabot" % (org, repo)
    template: str = """Please update dependabot flagged dependencies in %s

%s lists the following updates:
%s
Since a '%s' severity issue is present, tentatively adding the 'security/%s' label. At the time of filing, the above is untriaged. When updating the above checklist, please add supporting github comments as triaged, not affected or remediated. Dependabot only reported against the default branch so please be sure to check any other supported branches when researching/fixing.

Thanks!

References:
 * https://docs.influxdata.io/development/security/issue_handling/
 * https://docs.influxdata.io/development/security/issue_response/#developers
""" % (
        repo,
        url,
        checklist,
        sev[highest],
        priority,
    )

    print(template)
    print("## end template")


def getGHAlertsUpdatedReport(
    org: str,
    since: int = 0,
    repos: List[str] = [],
    excluded_repos: List[str] = [],
    with_templates: bool = False,
) -> None:
    """Obtain list of URLs that have received a vulnerability update since last run"""
    enabled: List[str]
    enabled, _ = _getGHAlertsEnabled(org, repos, excluded_repos)

    # convert since to a date string that we can lexigraphically compare to the
    # github string
    if not isinstance(since, int) or since < 0:
        raise ValueError
    since_str: str = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(since))

    # find updates
    updated: Dict[str, List[Dict[str, str]]] = {}
    dismissed: Dict[str, List[Dict[str, str]]] = {}
    count: int = 0

    # for large numbers of 'enabled', we might get rate limited:
    # https://docs.github.com/en/graphql/overview/resource-limitations
    repo: str
    for repo in sorted(enabled):
        count += 1
        updateProgress(count / len(enabled), prefix="Collecting alerts: ")

        cursorAfter: str = ""
        while True:
            query: str = """
    {
      repository(name: "%s", owner: "%s") {
        vulnerabilityAlerts(first: 100%s) {
          nodes {
            createdAt
            dismissedAt
            dismissReason
            dismisser {
              name
            }
            securityVulnerability {
              package {
                name
              }
              severity
            }
            vulnerableManifestPath
            securityAdvisory {
              permalink
            }
          }
          pageInfo {
            startCursor
            endCursor
            hasNextPage
          }
        }
      }
    }
    """ % (
                repo,
                org,
                cursorAfter,
            )
            res: Dict[str, Any] = _queryGraphQL(query)
            # import json
            # print(json.dumps(res, indent=2))
            n: Dict[str, Any]
            for n in res["data"]["repository"]["vulnerabilityAlerts"]["nodes"]:
                # skip any that are dismissed
                if n["dismissedAt"] is not None and n["dismissedAt"] > since_str:
                    if repo not in dismissed:
                        dismissed[repo] = []

                    dismissed[repo].append(
                        {
                            "pkg": n["securityVulnerability"]["package"]["name"],
                            "severity": n["securityVulnerability"]["severity"].lower(),
                            "path": n["vulnerableManifestPath"],
                            "ghsa": n["securityAdvisory"]["permalink"],
                            "dismissed": n["dismissedAt"],
                            "name": n["dismisser"]["name"],
                            "reason": n["dismissReason"],
                        }
                    )
                elif n["createdAt"] > since_str:
                    if repo not in updated:
                        updated[repo] = []

                    updated[repo].append(
                        {
                            "pkg": n["securityVulnerability"]["package"]["name"],
                            "severity": n["securityVulnerability"]["severity"].lower(),
                            "path": n["vulnerableManifestPath"],
                            "ghsa": n["securityAdvisory"]["permalink"],
                            "created": n["createdAt"],
                        }
                    )

            # deal with pagination
            if not res["data"]["repository"]["vulnerabilityAlerts"]["pageInfo"][
                "hasNextPage"
            ]:
                break
            cursorAfter: str = (
                ', after: "%s"'
                % res["data"]["repository"]["vulnerabilityAlerts"]["pageInfo"][
                    "endCursor"
                ]
            )

    if len(updated) == 0:
        print("No vulnerability alerts for the specified repos.")
    else:
        print("Vulnerability alerts:")
        for repo in sorted(updated.keys()):
            if with_templates:
                _printGHAlertsUpdatedTemplates(org, repo, updated[repo])
                print("")
            _printGHAlertsUpdatedSummary(org, repo, updated[repo])

    if len(dismissed) > 0:
        print("Dismissed vulnerability alerts:")
        for repo in sorted(dismissed.keys()):
            print("")
            _printGHAlertsDismissedSummary(org, repo, dismissed[repo])


def main() -> None:
    parser: argparse.ArgumentParser = argparse.ArgumentParser(
        prog="cve-report-updated-bugs",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description="Generate reports on security issue bug updates",
        epilog=textwrap.dedent(
            """\
Example usage:

  # first export a GitHub Personal Access Token that can read issues:
  $  export GHTOKEN=...

  # Show issues that are referenced in open CVE data that have been
  # updated since last week
  $ cve-report-updated-bugs --show-updated \\
      --gh-org foo --since $(date --date "7 days ago" "+%s")

  # Show list of issues for specific repos in an org with different
  # labels
  $ cve-report-updated-bugs --show-missing \\
      --gh-org foo \\
      --gh-labels="bar:baz" \\
      --gh-repos=norg,corge,qux

  # Show GitHub dependabot alerts since last stamp file
  $ cve-report-updated-bugs --gh-show-alerts \\
      --gh-org foo \\
      --since-stamp /path/to/stamp
        """
        ),
    )
    parser.add_argument(
        "--show-combined",
        dest="show_combined",
        help="show dependabot, missing and updates",
        action="store_true",
    )
    parser.add_argument(
        "--show-missing",
        dest="show_missing",
        help="show URLs missing from CVE info",
        action="store_true",
    )
    parser.add_argument(
        "--show-updated",
        dest="show_updated",
        help="show URLs that have been updated since --since TIME",
        action="store_true",
    )
    parser.add_argument(
        "--gh-org",
        dest="gh_org",
        type=str,
        help="GitHub URLs must belong to ORG",
        default=None,
    )
    parser.add_argument(
        "--gh-repos",
        dest="gh_repos",
        type=str,
        help="Comma-separated list of GitHub repos",
        default=None,
    )
    parser.add_argument(
        "--gh-excluded-repos",
        dest="gh_excluded_repos",
        type=str,
        help="Comma-separated list of GitHub repos",
        default=None,
    )
    # The GitHub API uses:
    #   &labels=foo     - issue has 'foo' label
    #   &labels=bar,baz - issue has 'bar' and 'baz' labels
    #
    # --gh-labels uses ',' for AND and ':' for OR such that
    #   foo             - show issues with 'foo' label
    #   foo:bar         - show issues with 'foo' or 'bar' label
    #   foo:bar,baz     - show issues with 'foo' label or 'bar' and 'baz labels
    parser.add_argument(
        "--gh-labels",
        dest="gh_labels",
        type=str,
        help="Colon-separated list of GitHub labels (use commans for ANDed labels)",
        default=None,
    )
    # Consider that --gh-labels=foo returns all issues with the label 'foo'.
    # Sometimes it is useful to list all issues with the label foo but without
    # label 'bar'. Use --gh-labels=foo --gh-skip-labels=bar
    parser.add_argument(
        "--gh-skip-labels",
        dest="gh_skip_labels",
        type=str,
        help="Colon-separated list of GitHub labels to skip issues when present",
        default=None,
    )
    parser.add_argument(
        "--gh-show-alerts-repo-status",
        dest="gh_show_alerts_repo_status",
        help="show status of GitHub vulnerability alerts (dependabot) by repo",
        action="store_true",
    )
    parser.add_argument(
        "--gh-show-alerts",
        dest="gh_show_alerts",
        help="show GitHub vulnerability alerts (dependabot)",
        action="store_true",
    )
    parser.add_argument(
        "--gh-show-alerts-templates",
        dest="gh_show_alerts_templates",
        help="show GitHub vulnerability alerts (dependabot)",
        action="store_true",
    )
    parser.add_argument(
        "--since",
        dest="since",
        type=int,
        help="Report bug updates since TIME (in epoch seconds)",
        default=0,
    )
    parser.add_argument(
        "--since-stamp",
        dest="since_stamp",
        type=str,
        help="Report bug updates since last TIME based on stamp file",
        default=None,
    )

    args: argparse.Namespace = parser.parse_args()

    if args.show_combined:
        args.show_updated = True
        args.show_missing = True
        args.gh_show_alerts = True

    if (
        not args.show_missing
        and not args.show_updated
        and not args.gh_show_alerts
        and not args.gh_show_alerts_repo_status
    ):
        error(
            "Please specify one of --show-missing, --show-updated, --gh-show-alerts or --gh-show-alerts-repo-status"
        )
    elif (args.show_updated or args.gh_show_alerts) and (
        args.since == 0 and args.since_stamp is None
    ):
        error(
            "Please specify --since and/or --since-stamp with --show-updated/--gh-show-alerts"
        )
    elif args.gh_show_alerts_templates and not args.gh_show_alerts:
        error("Please specify --gh-show-alerts with --gh-show-alerts-templates")

    if "GHTOKEN" not in os.environ:
        error("Please export GitHub personal access token as GHTOKEN")

    cveDirs: Dict[str, str] = getConfigCveDataPaths()
    compat: bool = getConfigCompatUbuntu()

    # First, check the syntax of our CVEs
    checkSyntax(cveDirs, compat, untriagedOk=True)

    # Gather the CVEs (including retired/ and ignored/)
    cves: List[CVE] = []
    cve_fn: str
    for cve_fn in _getCVEPaths(cveDirs):
        cves.append(CVE(fn=cve_fn, compatUbuntu=compat, untriagedOk=True))

    if args.show_updated or args.gh_show_alerts:
        # Allow for specifying --since and --since-stamp together. Eg:
        #   --since alone just sets 'since' with no stamp file
        #   --since-stamp alone where stamp file doesn't exists defaults to '0'
        #     then creates the stamp file
        #   --since-stamp alone where stamp file exists uses mtime of stamp
        #     file then updates the stamp file
        #   --since with --since-stamp sets 'since' to --since and then updates
        #     stamp file
        since: int = args.since
        if (
            args.since == 0
            and args.since_stamp is not None
            and os.path.exists(args.since_stamp)
        ):
            since = int(os.path.getmtime(args.since_stamp))

        if args.gh_show_alerts:
            if args.show_combined:
                print("# Alerts")

            repos: List[str] = []
            if args.gh_repos is not None:
                repos = args.gh_repos.split(",")

            excluded_repos: List[str] = []
            if args.gh_excluded_repos is not None:
                excluded_repos = args.gh_excluded_repos.split(",")

            getGHAlertsUpdatedReport(
                args.gh_org,
                since=since,
                repos=repos,
                excluded_repos=excluded_repos,
                with_templates=args.gh_show_alerts_templates,
            )

        if args.show_updated:
            if args.show_combined:
                print("\n# Updates")
            getUpdatedReport(cves, args.gh_org, since=since)

        if args.since_stamp is not None:
            pathlib.Path(args.since_stamp).touch()

    if args.show_missing:
        if args.show_combined:
            print("\n# Missing")

        repos: List[str] = []
        if args.gh_repos is not None:
            repos = args.gh_repos.split(",")

        excluded_repos: List[str] = []
        if args.gh_excluded_repos is not None:
            excluded_repos = args.gh_excluded_repos.split(",")

        labels: List[str] = []
        if args.gh_labels is not None:
            labels = args.gh_labels.split(":")
        skip_labels: List[str] = []
        if args.gh_skip_labels is not None:
            skip_labels = args.gh_skip_labels.split(":")
        getMissingReport(
            cves,
            args.gh_org,
            repos=repos,
            excluded_repos=excluded_repos,
            labels=labels,
            skip_labels=skip_labels,
        )

    if args.gh_show_alerts_repo_status:
        repos: List[str] = []
        if args.gh_repos is not None:
            repos = args.gh_repos.split(",")

        excluded_repos: List[str] = []
        if args.gh_excluded_repos is not None:
            excluded_repos = args.gh_excluded_repos.split(",")

        getGHAlertsStatusReport(args.gh_org, repos=repos, excluded_repos=excluded_repos)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        error("Aborted.")
