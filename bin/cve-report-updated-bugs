#!/usr/bin/env python3

import argparse
import copy
import os
import requests
import textwrap
import time

from cvelib.cve import checkSyntax, _getCVEPaths, CVE
from cvelib.common import (
    getConfigCveDataPaths,
    getConfigCompatUbuntu,
    error,
    rePatterns,
)


def _requestGet(url, headers={}, params={}):
    """Wrapper around requests.get()"""
    hdrs = copy.deepcopy(headers)
    if len(hdrs) == 0:
        if "GHTOKEN" in os.environ:
            hdrs["Authorization"] = "token %s" % os.getenv("GHTOKEN")

    # print("DEBUG: url=%s, headers=%s, params=%s" % (url, hdrs, params))
    r = requests.get(url, headers=hdrs, params=params)
    if r.status_code >= 400:
        error("Problem fetching %s:\n%s" % (url, r.json()))

    return r.json()


def _getGHReposAll(org):
    """Obtain the list of GitHub repos for the specified org"""
    url = "https://api.github.com/orgs/%s/repos" % org
    params = {"accept": "application/vnd.github.v3+json", "per_page": 100}

    repos = []
    print("Fetching list of repos: ", end="", flush=True)
    count = 0
    while True:
        count += 1
        print(".", end="", flush=True)
        params["page"] = count

        resj = _requestGet(url, params=params)
        if len(resj) == 0:
            print(" done!")
            break

        for repo in resj:
            if "name" in repo:
                repos.append(repo["name"])

    return repos


def _getGHIssuesForRepo(repo, org, labels=[]):
    """Obtain the list of GitHub issues for the specified repo and org"""
    url = "https://api.github.com/repos/%s/%s/issues" % (org, repo)
    params = {"accept": "application/vnd.github.v3+json", "per_page": 100}
    query_labels = [None]
    if len(labels) > 0:
        query_labels = labels

    issues = []
    print(" %s/%s: " % (org, repo), end="", flush=True)
    for query_label in query_labels:
        count = 0
        while True:
            count += 1
            print(".", end="", flush=True)
            params["page"] = count

            if query_label is not None:
                params["labels"] = query_label

            resj = _requestGet(url, params=params)
            if len(resj) == 0:
                break

            for issue in resj:
                if "pull_request" in issue and len(issue["pull_request"]) > 0:
                    continue  # skip pull requests
                if "html_url" in issue:
                    issues.append(issue["html_url"])
    print(" done!")

    return sorted(issues)


def _getGHIssue(repo, org, number):
    """Obtain the GitHub issue for the specified repo, org and issue number"""
    url = "https://api.github.com/repos/%s/%s/issues/%d" % (org, repo, number)
    params = {"accept": "application/vnd.github.v3+json"}

    return _requestGet(url, params=params)


def _getKnownIssues(cves, filter_url=None):
    """Obtain the list of URLs in our CVE info"""

    def _collectable(url, filter):
        if rePatterns["github-issue"].match(url):
            if filter is None or "/%s/" % filter in url:
                return True
        return False

    urls = []
    for cve in cves:
        for u in cve.references + cve.bugs:
            url = u.split()[0]
            if _collectable(url, filter_url):
                # strip off GH comments
                if url.startswith("https://github.com") and "#" in url:
                    url = url.split("#")[0]
                if url not in urls:
                    urls.append(url)

    return urls


def getMissingReport(cves, org, repos=[], labels=[]):
    """Compare list of issues in issue trackers against our CVE data"""
    known_urls = _getKnownIssues(cves, filter_url=org)

    fetch_repos = repos
    if len(fetch_repos) == 0:
        fetch_repos = _getGHReposAll(org)

    gh_urls = []
    print("Fetching list of issues for:")
    for repo in sorted(fetch_repos):
        for url in _getGHIssuesForRepo(repo, org, labels=labels):
            if url not in known_urls and url not in gh_urls:
                gh_urls.append(url)

    print("Issues missing from CVE data:")
    for url in gh_urls:
        print(" %s" % url)


def getUpdatedReport(cves, org, since=0):
    """Obtain list of URLs that have received an update since last run"""
    urls = _getKnownIssues(cves, filter_url=org)

    # convert since to a date string that we can lexigraphically compare to the
    # github string
    if not isinstance(since, int) or since < 0:
        raise ValueError
    since_str = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(since))

    # find updates
    updated_urls = []
    for url in sorted(urls):
        # TODO: break this out
        if not rePatterns["github-issue"].match(url):
            continue  # only support github issues at this time
        tmp = url.split("/")

        # compare the issue's updated_at with our since time
        issue = _getGHIssue(tmp[4], tmp[3], int(tmp[6]))
        if "updated_at" in issue and issue["updated_at"] > since_str:
            updated_urls.append(url)

    print("Updated issues:")
    for url in updated_urls:
        print(" %s" % url)


def main():
    parser = argparse.ArgumentParser(
        prog="cve-report-updated-bugs",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description="Generate reports on security issue bug updates",
        epilog=textwrap.dedent(
            """\
Example usage:

  # first export a GitHub Personal Access Token that can read issues:
  $  export GHTOKEN=...

  # Show issues that are referenced in open CVE data that have been
  # updated since last week
  $ cve-report-updated-bugs --show-updated \\
      --gh-org foo --since $(date --date "7 days ago" "+%s")

  # Show list of issues for specific repos in an org with different
  # labels
  $ cve-report-updated-bugs --show-missing \\
      --gh-org foo \\
      --gh-labels="bar:baz" \\
      --gh-repos=norg,corge,qux
        """
        ),
    )
    parser.add_argument(
        "--show-missing",
        dest="show_missing",
        help="show URLs missing from CVE info",
        action="store_true",
    )
    parser.add_argument(
        "--show-updated",
        dest="show_updated",
        help="show URLs that have been updated since --since TIME",
        action="store_true",
    )
    parser.add_argument(
        "--gh-org",
        dest="gh_org",
        type=str,
        help="GitHub URLs must belong to ORG",
        default=None,
    )
    parser.add_argument(
        "--gh-repos",
        dest="gh_repos",
        type=str,
        help="Comma-separated list of GitHub repos",
        default=None,
    )
    # The GitHub API uses:
    #   &labels=foo     - issue has 'foo' label
    #   &lables=bar,baz - issue has 'bar' and 'baz' labels
    #
    # --gh-labels uses ',' for AND and ':' for OR such that
    #   foo             - show issues with 'foo' label
    #   foo:bar         - show issues with 'foo' or 'bar' label
    #   foo:bar,baz     - show issues with 'foo' label or 'bar' and 'baz labels
    parser.add_argument(
        "--gh-labels",
        dest="gh_labels",
        type=str,
        help="Colon-separated list of GitHub labels (use commans for ANDed labels)",
        default=None,
    )
    parser.add_argument(
        "--since",
        dest="since",
        type=int,
        help="Report bug updates since TIME (in epoch seconds)",
        default=0,
    )
    args = parser.parse_args()

    if not args.show_missing and not args.show_updated:
        error("Please specify one of --show-missing or --show-updated")
    elif args.show_updated and args.since == 0:
        error("Please specify --since with --show-updated")

    cveDirs = getConfigCveDataPaths()
    compat = getConfigCompatUbuntu()

    # First, check the syntax of our CVEs
    checkSyntax(cveDirs, compat, untriagedOk=True)

    # Gather the CVEs (including retired/ and ignored/)
    cves = []
    for cve_fn in _getCVEPaths(cveDirs):
        cves.append(CVE(fn=cve_fn, compatUbuntu=compat, untriagedOk=True))

    if args.show_updated:
        getUpdatedReport(cves, args.gh_org, since=args.since)
    if args.show_missing:
        repos = []
        if args.gh_repos is not None:
            repos = args.gh_repos.split(",")
        labels = []
        if args.gh_labels is not None:
            labels = args.gh_labels.split(":")
        getMissingReport(cves, args.gh_org, repos=repos, labels=labels)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        error("Aborted.")
